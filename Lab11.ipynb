{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fnVYJltfN8TN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f20QV-yaNZas",
    "outputId": "04610e80-48f0-45cc-c7fd-84446a13189e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "example text: PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists\n"
     ]
    }
   ],
   "source": [
    "path=get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    raw_text=f.read()\n",
    "\n",
    "print('corpus length:',len(raw_text))\n",
    "print('example text:',raw_text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-qGtVG3CN-hX"
   },
   "outputs": [],
   "source": [
    "tokens=raw_text.replace('--', ' ').split()\n",
    "cleaned_tokens=[]\n",
    "table=str.maketrans('','', string.punctuation)\n",
    "for word in tokens:\n",
    "    word=word.translate(table)\n",
    "    if word.isalpha():\n",
    "        cleaned_tokens.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N769sVlrTYw6",
    "outputId": "7d9019e2-0599-4441-9743-10afb26c5ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size:  5090\n",
      "filtered words:  5097\n"
     ]
    }
   ],
   "source": [
    "min_count=2\n",
    "unknown_token='<unk>'\n",
    "word2index={unknown_token: 0}\n",
    "index2word=[unknown_token]\n",
    "\n",
    "filtered_words=0\n",
    "counter=Counter(cleaned_tokens)\n",
    "for word, count in counter.items():\n",
    "    if count>=min_count:\n",
    "        index2word.append(word)\n",
    "        word2index[word]=len(word2index)\n",
    "    else:\n",
    "        filtered_words+=1\n",
    "\n",
    "num_classes=len(word2index)\n",
    "print('vocabulary size: ',num_classes)\n",
    "print('filtered words: ',filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ToHcYnRcTvOq",
    "outputId": "c027c85a-f564-444f-dc96-553c48d40b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence dimension:  (33342, 40)\n",
      "target dimension:  (33342, 5090)\n",
      "example sequence:\n",
      " [ 1  2  3  4  5  6  7  8  9  5 10 11 12 13  0  3 14 15 16 17 18 19 20 21\n",
      " 22 23 21 24 25 26 27  3 28 29 30 31 32  0 33 34]\n"
     ]
    }
   ],
   "source": [
    "step=3\n",
    "maxlen=40\n",
    "X=[]\n",
    "y=[]\n",
    "for i in range(0,len(cleaned_tokens)-maxlen,step):\n",
    "    sentence=cleaned_tokens[i:i+maxlen]\n",
    "    next_word=cleaned_tokens[i+maxlen]\n",
    "    X.append([word2index.get(word,0) for word in sentence])\n",
    "    y.append(word2index.get(next_word,0))\n",
    "X=np.array(X)\n",
    "Y=to_categorical(y,num_classes)\n",
    "print('sequence dimension: ',X.shape)\n",
    "print('target dimension: ',Y.shape)\n",
    "print('example sequence:\\n',X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUCkOYRfVDyb",
    "outputId": "1781d101-8a8f-49a3-8cbd-9b438be70661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 50)            254500    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               314368    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5090)              1308130   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,876,998\n",
      "Trainable params: 1,876,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_size=50\n",
    "lstm_size=256\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(num_classes,embedding_size,input_length=maxlen))\n",
    "model1.add(LSTM(lstm_size))\n",
    "model1.add(Dense(num_classes,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MnLrPhgVmqq",
    "outputId": "971b6455-2240-48da-b2bb-ecc1e253fdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model checkpoint address:  lstm_weights1.hdf5\n",
      "Epoch 1/40\n",
      "834/834 [==============================] - 18s 8ms/step - loss: 6.3642 - val_loss: 6.2208\n",
      "Epoch 2/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 5.8522 - val_loss: 6.1634\n",
      "Epoch 3/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 5.6103 - val_loss: 6.1831\n",
      "Epoch 4/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 5.3980 - val_loss: 6.2661\n",
      "Epoch 5/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 5.1532 - val_loss: 6.3708\n",
      "Epoch 6/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 4.8962 - val_loss: 6.4794\n",
      "Epoch 7/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 4.6059 - val_loss: 6.6331\n",
      "Epoch 8/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 4.3007 - val_loss: 6.8160\n",
      "Epoch 9/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 3.9874 - val_loss: 7.0006\n",
      "Epoch 10/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 3.6634 - val_loss: 7.1985\n",
      "Epoch 11/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 3.3309 - val_loss: 7.3964\n",
      "Epoch 12/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 3.0149 - val_loss: 7.6178\n",
      "Epoch 13/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 2.7126 - val_loss: 7.8533\n",
      "Epoch 14/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 2.4331 - val_loss: 8.0787\n",
      "Epoch 15/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 2.1732 - val_loss: 8.2784\n",
      "Epoch 16/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 1.9355 - val_loss: 8.5254\n",
      "Epoch 17/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 1.7220 - val_loss: 8.7639\n",
      "Epoch 18/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 1.5193 - val_loss: 8.9462\n",
      "Epoch 19/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 1.3401 - val_loss: 9.2133\n",
      "Epoch 20/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 1.1787 - val_loss: 9.4238\n",
      "Epoch 21/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 1.0329 - val_loss: 9.6261\n",
      "Epoch 22/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.8985 - val_loss: 9.8812\n",
      "Epoch 23/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.7724 - val_loss: 10.0690\n",
      "Epoch 24/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.6618 - val_loss: 10.3246\n",
      "Epoch 25/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.5729 - val_loss: 10.5352\n",
      "Epoch 26/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.4897 - val_loss: 10.7645\n",
      "Epoch 27/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 0.4190 - val_loss: 10.9635\n",
      "Epoch 28/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.3612 - val_loss: 11.1501\n",
      "Epoch 29/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 0.3059 - val_loss: 11.3852\n",
      "Epoch 30/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 0.2575 - val_loss: 11.5772\n",
      "Epoch 31/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.2333 - val_loss: 11.7385\n",
      "Epoch 32/40\n",
      "834/834 [==============================] - 6s 8ms/step - loss: 0.1985 - val_loss: 11.9381\n",
      "Epoch 33/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.1596 - val_loss: 12.1006\n",
      "Epoch 34/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.1436 - val_loss: 12.2844\n",
      "Epoch 35/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.1543 - val_loss: 12.3745\n",
      "Epoch 36/40\n",
      "834/834 [==============================] - 7s 9ms/step - loss: 0.1567 - val_loss: 12.5676\n",
      "Epoch 37/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.1231 - val_loss: 12.7112\n",
      "Epoch 38/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.0854 - val_loss: 12.8533\n",
      "Epoch 39/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.0589 - val_loss: 13.0329\n",
      "Epoch 40/40\n",
      "834/834 [==============================] - 7s 8ms/step - loss: 0.1321 - val_loss: 12.9632\n"
     ]
    }
   ],
   "source": [
    "epochs=40\n",
    "batch_size=32\n",
    "validation_split=0.2\n",
    "address1='lstm_weights1.hdf5'\n",
    "print('model checkpoint address: ',address1)\n",
    "\n",
    "history=model1.fit(X,Y,batch_size=batch_size, \n",
    "                            epochs=epochs, verbose=1,\n",
    "                            validation_split=validation_split)\n",
    "\n",
    "model_info={'history': history,'model':model1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GEw_P2PxW-8-"
   },
   "outputs": [],
   "source": [
    "def check_prediction(model, num_predict):\n",
    "    true_print_out='Actual words: '\n",
    "    pred_print_out='Predicted words: '\n",
    "    for i in range(num_predict):\n",
    "        x=X[i]\n",
    "        prediction=model.predict(x[np.newaxis, :], verbose = 0)\n",
    "        index=np.argmax(prediction)\n",
    "        true_print_out+=index2word[y[i]]+' '\n",
    "        pred_print_out+=index2word[index]+' '\n",
    "\n",
    "    print(true_print_out)\n",
    "    print(pred_print_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvM_10uqcghr",
    "outputId": "c6ec5788-e598-4b13-e4da-e8977bc5d912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual words: they paid to been unseemly <unk> certainly never to and \n",
      "Predicted words: they paid to been unseemly <unk> certainly never to and \n"
     ]
    }
   ],
   "source": [
    "num_predict=10\n",
    "model=model_info['model']\n",
    "check_prediction(model,num_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1sTgsHAdvx0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
